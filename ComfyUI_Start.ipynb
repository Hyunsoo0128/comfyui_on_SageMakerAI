{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "411b9ea0-fe62-45a2-99a6-df9ba31aa706",
   "metadata": {},
   "source": [
    "### ComfyUI 서버 실행 및 접속 ###\n",
    "이 셀은 앞서 설치하고 준비한 ComfyUI를 웹 서버로 실행하는 역할을 합니다. 서버가 실행되면 웹 브라우저를 통해 ComfyUI의 노드 기반 인터페이스에 접속하여 이미지 생성을 시작할 수 있습니다.\n",
    "\n",
    "1. 코드 설명\n",
    "args = \"--preview-method auto --enable-cors-header --use-pytorch-cross-attention\"\n",
    "\n",
    "이 부분은 ComfyUI 서버를 시작할 때 적용할 추가 옵션들을 설정합니다.\n",
    "\n",
    "--preview-method auto: 이미지 생성 중간 과정을 보여주는 방식을 자동으로 설정합니다.\n",
    "\n",
    "--enable-cors-header: SageMaker와 같은 클라우드 환경에서 웹 인터페이스(프론트엔드)와 서버(백엔드)가 원활하게 통신할 수 있도록 허용하는 중요한 옵션입니다.\n",
    "\n",
    "--use-pytorch-cross-attention: PyTorch의 최적화된 연산 방식을 사용하여 성능을 향상시키는 옵션입니다.\n",
    "\n",
    "launch_comfy(args)\n",
    "\n",
    "ComfyUI/main.py 스크립트를 위에서 설정한 args 옵션과 함께 실행하여 서버를 시작하는 함수입니다.\n",
    "\n",
    "2. SageMaker Studio에서 접속하는 방법\n",
    "셀을 실행하면 출력 창에 http://127.0.0.1:8188 와 같은 로컬 주소가 나타납니다. 하지만 이 주소로는 SageMaker 환경에 직접 접속할 수 없습니다. 대신 아래의 방법으로 접속 주소를 변경해야 합니다.\n",
    "\n",
    "현재 JupyterLab 주소 확인\n",
    "먼저, 현재 사용 중인 웹 브라우저의 주소창을 확인합니다. 아래와 비슷한 형태일 것입니다.\n",
    "\n",
    "https://<스튜디오-ID>.studio.<리전>.sagemaker.aws/jupyter/default/lab\n",
    "\n",
    "기본 URL 추출\n",
    "위 주소에서 /lab 부분을 제외한 앞부분을 복사합니다.\n",
    "\n",
    "https://<스튜디오-ID>.studio.<리전>.sagemaker.aws/jupyter/default\n",
    "\n",
    "프록시 경로와 포트 번호 추가\n",
    "복사한 기본 URL 뒤에 /proxy/<포트번호>/를 추가합니다. ComfyUI의 기본 포트는 8188 입니다.\n",
    "\n",
    "/proxy/8188/\n",
    "\n",
    "최종 접속 URL 예시\n",
    "만약 내 JupyterLab 주소가:\n",
    "https://d-abcdef12345.studio.us-east-1.sagemaker.aws/jupyter/default/lab\n",
    "\n",
    "ComfyUI에 접속할 주소는:\n",
    "https://d-abcdef12345.studio.us-east-1.sagemaker.aws/jupyter/default/proxy/8188/\n",
    "\n",
    "이 최종 URL을 새 브라우저 탭에 입력하여 ComfyUI 인터페이스에 접속할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f263bfd-ed76-47e3-9c9f-eb17eb37469a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-24T23:25:16.917619Z",
     "iopub.status.busy": "2025-07-24T23:25:16.917207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rembg in /opt/conda/lib/python3.12/site-packages (2.0.67)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.12/site-packages (from rembg) (4.23.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from rembg) (2.2.6)\n",
      "Requirement already satisfied: opencv-python-headless in /opt/conda/lib/python3.12/site-packages (from rembg) (4.12.0.88)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from rembg) (11.3.0)\n",
      "Requirement already satisfied: pooch in /opt/conda/lib/python3.12/site-packages (from rembg) (1.8.2)\n",
      "Requirement already satisfied: pymatting in /opt/conda/lib/python3.12/site-packages (from rembg) (1.1.14)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.12/site-packages (from rembg) (0.25.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from rembg) (1.15.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from rembg) (4.67.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.12/site-packages (from jsonschema->rembg) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.12/site-packages (from jsonschema->rembg) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.12/site-packages (from jsonschema->rembg) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from jsonschema->rembg) (0.26.0)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /opt/conda/lib/python3.12/site-packages (from referencing>=0.28.4->jsonschema->rembg) (4.14.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from pooch->rembg) (4.3.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from pooch->rembg) (24.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.12/site-packages (from pooch->rembg) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch->rembg) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch->rembg) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch->rembg) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.19.0->pooch->rembg) (2025.7.14)\n",
      "Requirement already satisfied: numba!=0.49.0 in /opt/conda/lib/python3.12/site-packages (from pymatting->rembg) (0.61.2)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/conda/lib/python3.12/site-packages (from numba!=0.49.0->pymatting->rembg) (0.44.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/conda/lib/python3.12/site-packages (from scikit-image->rembg) (3.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /opt/conda/lib/python3.12/site-packages (from scikit-image->rembg) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.12/site-packages (from scikit-image->rembg) (2025.6.11)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.12/site-packages (from scikit-image->rembg) (0.4)\n",
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease                       \n",
      "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease               \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease             \n",
      "Hit:5 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libgl1-mesa-glx is already the newest version (23.0.4-0ubuntu1~22.04.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 6 not upgraded.\n",
      "Wait for local URL to appear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python: No module named uv\n",
      "Failed to execute startup-script: /home/sagemaker-user/ComfyUI/custom_nodes/ComfyUI-Manager/prestartup_script.py / Command '['/opt/conda/bin/python', '-m', 'uv', 'pip', 'freeze']' returned non-zero exit status 1.\n",
      "\n",
      "Prestartup times for custom nodes:\n",
      "   0.2 seconds (PRESTARTUP FAILED): /home/sagemaker-user/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "\n",
      "Checkpoint files will always be loaded safely.\n",
      "Total VRAM 22503 MB, total RAM 31737 MB\n",
      "pytorch version: 2.7.1+cu126\n",
      "Set vram state to: NORMAL_VRAM\n",
      "Device: cuda:0 NVIDIA A10G : cudaMallocAsync\n",
      "Using pytorch attention\n",
      "Python version: 3.12.9 | packaged by conda-forge | (main, Feb 14 2025, 08:00:06) [GCC 13.3.0]\n",
      "ComfyUI version: 0.3.45\n",
      "ComfyUI frontend version: 1.23.4\n",
      "[Prompt Server] web root: /opt/conda/lib/python3.12/site-packages/comfyui_frontend_package/static\n",
      "### Loading: ComfyUI-Manager (V3.34.5)\n",
      "[ComfyUI-Manager] network_mode: public\n",
      "[ComfyUI-Manager] Since --preview-method is set, ComfyUI-Manager's preview method feature will be ignored.\n",
      "### ComfyUI Revision: 3678 [9a470e07] *DETACHED | Released on '2025-07-21'\n",
      "\u001b[36;20m[/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ckpts path: /home/sagemaker-user/ComfyUI/custom_nodes/comfyui_controlnet_aux/ckpts\u001b[0m\n",
      "\u001b[36;20m[/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using symlinks: False\u001b[0m\n",
      "\u001b[36;20m[/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_controlnet_aux] | INFO -> Using ort providers: ['CUDAExecutionProvider', 'DirectMLExecutionProvider', 'OpenVINOExecutionProvider', 'ROCMExecutionProvider', 'CPUExecutionProvider', 'CoreMLExecutionProvider']\u001b[0m\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/alter-list.json\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/extension-node-map.json\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/model-list.json\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/github-stats.json\n",
      "[ComfyUI-Manager] default cache updated: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json\n",
      "2025-07-24 23:25:28.456352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753399528.471978   27611 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753399528.476891   27611 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-24 23:25:28.492576: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "Import times for custom nodes:\n",
      "   0.0 seconds: /home/sagemaker-user/ComfyUI/custom_nodes/websocket_image_save.py\n",
      "   0.0 seconds: /home/sagemaker-user/ComfyUI/custom_nodes/ComfyUI-segment-anything-2\n",
      "   0.0 seconds: /home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus\n",
      "   0.2 seconds: /home/sagemaker-user/ComfyUI/custom_nodes/ComfyUI-Manager\n",
      "   0.5 seconds: /home/sagemaker-user/ComfyUI/custom_nodes/comfyui_controlnet_aux\n",
      "   4.5 seconds: /home/sagemaker-user/ComfyUI/custom_nodes/was-ns\n",
      "\n",
      "Context impl SQLiteImpl.\n",
      "Will assume non-transactional DDL.\n",
      "No target revision found.\n",
      "Starting server\n",
      "\n",
      "To see the GUI go to: http://127.0.0.1:8188\n",
      "[ComfyUI-Manager] default cache updated: https://api.comfy.org/nodes\n",
      "[ComfyUI-Manager] All startup tasks have been completed.\n",
      "got prompt\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Device set to use cuda:0\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 17551.009757995605 159.55708122253418 True\n",
      "Requested to load CLIPVisionModelProjection\n",
      "loaded completely 19214.75267677307 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "Requested to load ControlNet\n",
      "Requested to load ControlNet\n",
      "Requested to load ControlNet\n",
      "loaded completely 17956.568926620483 4897.0483474731445 True\n",
      "loaded completely 13059.472666549682 689.0852355957031 True\n",
      "loaded completely 12370.387430953979 689.0852355957031 True\n",
      "loaded completely 11681.302195358276 689.0852355957031 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\n",
      "!!! Exception during processing !!! mat1 and mat2 shapes cannot be multiplied (154x2048 and 768x320)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 427, in execute\n",
      "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 270, in get_output_data\n",
      "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 244, in _async_map_node_over_list\n",
      "    await process_inputs(input_dict, i)\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 232, in process_inputs\n",
      "    result = f(**inputs)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/nodes.py\", line 1516, in sample\n",
      "    return common_ksampler(model, seed, steps, cfg, sampler_name, scheduler, positive, negative, latent_image, denoise=denoise)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/nodes.py\", line 1483, in common_ksampler\n",
      "    samples = comfy.sample.sample(model, noise, steps, cfg, sampler_name, scheduler, positive, negative, latent_image,\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/sample.py\", line 45, in sample\n",
      "    samples = sampler.sample(noise, positive, negative, cfg=cfg, latent_image=latent_image, start_step=start_step, last_step=last_step, force_full_denoise=force_full_denoise, denoise_mask=noise_mask, sigmas=sigmas, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 1143, in sample\n",
      "    return sample(self.model, noise, positive, negative, cfg, self.device, sampler, sigmas, self.model_options, latent_image=latent_image, denoise_mask=denoise_mask, callback=callback, disable_pbar=disable_pbar, seed=seed)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 1033, in sample\n",
      "    return cfg_guider.sample(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 1018, in sample\n",
      "    output = executor.execute(noise, latent_image, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/patcher_extension.py\", line 111, in execute\n",
      "    return self.original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 986, in outer_sample\n",
      "    output = self.inner_sample(noise, latent_image, device, sampler, sigmas, denoise_mask, callback, disable_pbar, seed)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 969, in inner_sample\n",
      "    samples = executor.execute(self, sigmas, extra_args, callback, noise, latent_image, denoise_mask, disable_pbar)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/patcher_extension.py\", line 111, in execute\n",
      "    return self.original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 748, in sample\n",
      "    samples = self.sampler_function(model_k, noise, sigmas, extra_args=extra_args, callback=k_callback, disable=disable_pbar, **self.extra_options)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/k_diffusion/sampling.py\", line 190, in sample_euler\n",
      "    denoised = model(x, sigma_hat * s_in, **extra_args)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 400, in __call__\n",
      "    out = self.inner_model(x, sigma, model_options=model_options, seed=seed)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 949, in __call__\n",
      "    return self.predict_noise(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 952, in predict_noise\n",
      "    return sampling_function(self.inner_model, x, timestep, self.conds.get(\"negative\", None), self.conds.get(\"positive\", None), self.cfg, model_options=model_options, seed=seed)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 380, in sampling_function\n",
      "    out = calc_cond_batch(model, conds, x, timestep, model_options)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 206, in calc_cond_batch\n",
      "    return executor.execute(model, conds, x_in, timestep, model_options)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/patcher_extension.py\", line 111, in execute\n",
      "    return self.original(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/samplers.py\", line 320, in _calc_cond_batch\n",
      "    c['control'] = control.get_control(input_x, timestep_, c, len(cond_or_uncond), transformer_options)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/controlnet.py\", line 220, in get_control\n",
      "    control_prev = self.previous_controlnet.get_control(x_noisy, t, cond, batched_number, transformer_options)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/controlnet.py\", line 220, in get_control\n",
      "    control_prev = self.previous_controlnet.get_control(x_noisy, t, cond, batched_number, transformer_options)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/controlnet.py\", line 273, in get_control\n",
      "    control = self.control_model(x=x_noisy.to(dtype), hint=self.cond_hint, timesteps=timestep.to(dtype), context=context.to(dtype), **extra)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/cldm/cldm.py\", line 426, in forward\n",
      "    h = module(h, emb, context)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/ldm/modules/diffusionmodules/openaimodel.py\", line 69, in forward\n",
      "    return forward_timestep_embed(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/ldm/modules/diffusionmodules/openaimodel.py\", line 44, in forward_timestep_embed\n",
      "    x = layer(x, context, transformer_options)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/ldm/modules/attention.py\", line 863, in forward\n",
      "    x = block(x, context=context[i], transformer_options=transformer_options)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/ldm/modules/attention.py\", line 789, in forward\n",
      "    n = self.attn2(n, context=context_attn2, value=value_attn2)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/ldm/modules/attention.py\", line 635, in forward\n",
      "    k = self.to_k(context)\n",
      "        ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/comfy/ops.py\", line 86, in forward\n",
      "    return super().forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/linear.py\", line 125, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: mat1 and mat2 shapes cannot be multiplied (154x2048 and 768x320)\n",
      "\n",
      "Prompt executed in 8.92 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Security scan\n",
      "DWPose: Onnxruntime with acceleration providers detected\n",
      "FETCH ComfyRegistry Data: 5/92\n",
      "\u001b[34mWAS Node Suite: \u001b[0mOpenCV Python FFMPEG support is enabled\u001b[0m\n",
      "\u001b[34mWAS Node Suite \u001b[93mWarning: \u001b[0m`ffmpeg_bin_path` is not set in `/home/sagemaker-user/ComfyUI/custom_nodes/was-ns/was_suite_config.json` config file. Will attempt to use system ffmpeg binaries if available.\u001b[0m\n",
      "\u001b[34mWAS Node Suite: \u001b[0mFinished.\u001b[0m \u001b[32mLoaded\u001b[0m \u001b[0m220\u001b[0m \u001b[32mnodes successfully.\u001b[0m\n",
      "\n",
      "\t\u001b[3m\u001b[93m\"Art is not freedom from discipline, but disciplined freedom.\"\u001b[0m\u001b[3m - John F. Kennedy\u001b[0m\n",
      "\n",
      "FETCH ComfyRegistry Data: 10/92\n",
      "FETCH ComfyRegistry Data: 15/92\n",
      "FETCH ComfyRegistry Data: 20/92\n",
      "FETCH ComfyRegistry Data: 25/92\n",
      "FETCH ComfyRegistry Data: 30/92\n",
      "FETCH ComfyRegistry Data: 35/92\n",
      "FETCH ComfyRegistry Data: 40/92\n",
      "FETCH ComfyRegistry Data: 45/92\n",
      "FETCH ComfyRegistry Data: 50/92\n",
      "FETCH ComfyRegistry Data: 55/92\n",
      "FETCH ComfyRegistry Data: 60/92\n",
      "FETCH ComfyRegistry Data: 65/92\n",
      "FETCH ComfyRegistry Data: 70/92\n",
      "FETCH ComfyRegistry Data: 75/92\n",
      "FETCH ComfyRegistry Data: 80/92\n",
      "FETCH ComfyRegistry Data: 85/92\n",
      "FETCH ComfyRegistry Data: 90/92\n",
      "FETCH ComfyRegistry Data [DONE]\n",
      "FETCH DATA from: https://raw.githubusercontent.com/ltdrdata/ComfyUI-Manager/main/custom-node-list.json [DONE]\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "got prompt\n",
      "Requested to load ControlNet\n",
      "loaded completely 10876.886446762084 2395.547637939453 True\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.91 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 32.90 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.13 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.75it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.87 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.20 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.48 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.48 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.47it/s]\n",
      "Prompt executed in 33.63 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.09 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.49 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.21 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "got prompt\n",
      "Prompt executed in 33.57 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.11 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.05 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 32.94 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 32.98 seconds\n",
      "got prompt\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 6807.592384338379 159.55708122253418 True\n",
      "Requested to load SDXL\n",
      "loaded completely 8435.252138900756 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 45.04 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.15 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.14 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.37 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.28 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.10 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.24 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.16 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.45 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:04<00:00,  4.48it/s]\n",
      "Prompt executed in 33.20 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.77it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.77it/s]\n",
      "Prompt executed in 39.85 seconds\n",
      "got prompt\n",
      "100%|██████████| 40/40 [00:22<00:00,  1.76it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.76it/s]\n",
      "Prompt executed in 39.64 seconds\n",
      "got prompt\n",
      "!!! Exception during processing !!! Error(s) in loading state_dict for ImageProjModel:\n",
      "\tsize mismatch for proj.weight: copying a param with shape torch.Size([8192, 1280]) from checkpoint, the shape in current model is torch.Size([8192, 1024]).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 427, in execute\n",
      "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 270, in get_output_data\n",
      "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 244, in _async_map_node_over_list\n",
      "    await process_inputs(input_dict, i)\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 232, in process_inputs\n",
      "    result = f(**inputs)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus/IPAdapterPlus.py\", line 758, in apply_ipadapter\n",
      "    work_model, face_image = ipadapter_execute(work_model, ipadapter_model, clip_vision, **ipa_args)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus/IPAdapterPlus.py\", line 386, in ipadapter_execute\n",
      "    ipa = IPAdapter(\n",
      "          ^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus/IPAdapterPlus.py\", line 70, in __init__\n",
      "    self.image_proj_model.load_state_dict(ipadapter_model[\"image_proj\"])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 2593, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for ImageProjModel:\n",
      "\tsize mismatch for proj.weight: copying a param with shape torch.Size([8192, 1280]) from checkpoint, the shape in current model is torch.Size([8192, 1024]).\n",
      "\n",
      "Prompt executed in 0.67 seconds\n",
      "got prompt\n",
      "Requested to load CLIPVisionModelProjection\n",
      "loaded completely 4790.339628982544 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Prompt executed in 75.49 seconds\n",
      "got prompt\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 3468.7170780181887 1560.802734375 True\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Prompt executed in 41.34 seconds\n",
      "got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Prompt executed in 40.86 seconds\n",
      "got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Prompt executed in 40.99 seconds\n",
      "got prompt\n",
      "loaded completely 4790.339628982544 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Prompt executed in 43.56 seconds\n",
      "got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.69 seconds\n",
      "got prompt\n",
      "loaded completely 6351.142370986939 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 54.94 seconds\n",
      "got prompt\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 3468.7170780181887 1560.802734375 True\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 53.00 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.57 seconds\n",
      "loaded completely 4790.339628982544 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 55.26 seconds\n",
      "got prompt\n",
      "Device set to use cuda:0\n",
      "loaded completely 6347.142370986939 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 65.38 seconds\n",
      "got prompt\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 5800.822364807129 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "loaded completely 5488.924502182007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 120.78 seconds\n",
      "got prompt\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 3464.7170780181887 1560.802734375 True\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.73 seconds\n",
      "got prompt\n",
      "Requested to load ControlNet\n",
      "Requested to load SDXL\n",
      "loaded completely 5859.942286300659 2396.797637939453 True\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 76.91 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.32 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.22 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      " 10%|█         | 2/20 [00:01<00:10,  1.73it/s]got prompt\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.28 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      " 70%|███████   | 14/20 [00:07<00:03,  1.84it/s]got prompt\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.24 seconds\n",
      "Requested to load ControlNet\n",
      "Requested to load SDXL\n",
      "loaded completely 5859.942286300659 2395.547637939453 True\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      " 25%|██▌       | 5/20 [00:02<00:07,  1.89it/s]got prompt\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 71.10 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      " 95%|█████████▌| 19/20 [00:11<00:00,  1.72it/s]got prompt\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.32 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "got prompt\n",
      "Prompt executed in 52.30 seconds\n",
      "Device set to use cuda:0\n",
      "loaded completely 4786.339628982544 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 67.05 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:10<00:00,  1.86it/s]\n",
      "Prompt executed in 52.30 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.87 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.87 seconds\n",
      "got prompt\n",
      "loaded completely 6347.142370986939 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 76.90 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.81 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "  5%|▌         | 2/40 [00:00<00:18,  2.08it/s]got prompt\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.86 seconds\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 5800.822364807129 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "loaded completely 5488.924502182007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      " 82%|████████▎ | 33/40 [00:19<00:04,  1.71it/s]got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 130.51 seconds\n",
      "loaded completely 6347.142370986939 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 76.77 seconds\n",
      "got prompt\n",
      "loaded completely 6347.142370986939 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 76.95 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.77 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 76.59 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.79 seconds\n",
      "got prompt\n",
      "loaded completely 6347.142370986939 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 76.77 seconds\n",
      "got prompt\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 5800.822364807129 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "loaded completely 5488.924502182007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 95.07 seconds\n",
      "got prompt\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 5800.822364807129 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 3522.953369140625 True\n",
      "Requested to load SDXL\n",
      "loaded completely 5488.924502182007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 129.95 seconds\n",
      "got prompt\n",
      "Requested to load CLIPVisionModelProjection\n",
      "loaded completely 6347.142370986939 3522.953369140625 True\n",
      "!!! Exception during processing !!! Error(s) in loading state_dict for Resampler:\n",
      "\tsize mismatch for proj_in.weight: copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape in current model is torch.Size([1280, 1664]).\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 427, in execute\n",
      "    output_data, output_ui, has_subgraph, has_pending_tasks = await get_output_data(prompt_id, unique_id, obj, input_data_all, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 270, in get_output_data\n",
      "    return_values = await _async_map_node_over_list(prompt_id, unique_id, obj, input_data_all, obj.FUNCTION, allow_interrupt=True, execution_block_cb=execution_block_cb, pre_execute_cb=pre_execute_cb)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 244, in _async_map_node_over_list\n",
      "    await process_inputs(input_dict, i)\n",
      "  File \"/home/sagemaker-user/ComfyUI/execution.py\", line 232, in process_inputs\n",
      "    result = f(**inputs)\n",
      "             ^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus/IPAdapterPlus.py\", line 758, in apply_ipadapter\n",
      "    work_model, face_image = ipadapter_execute(work_model, ipadapter_model, clip_vision, **ipa_args)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus/IPAdapterPlus.py\", line 386, in ipadapter_execute\n",
      "    ipa = IPAdapter(\n",
      "          ^^^^^^^^^^\n",
      "  File \"/home/sagemaker-user/ComfyUI/custom_nodes/comfyui_ipadapter_plus/IPAdapterPlus.py\", line 70, in __init__\n",
      "    self.image_proj_model.load_state_dict(ipadapter_model[\"image_proj\"])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 2593, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for Resampler:\n",
      "\tsize mismatch for proj_in.weight: copying a param with shape torch.Size([1280, 1280]) from checkpoint, the shape in current model is torch.Size([1280, 1664]).\n",
      "\n",
      "Prompt executed in 29.05 seconds\n",
      "got prompt\n",
      "Requested to load CLIPVisionModelProjection\n",
      "loaded completely 6347.142370986939 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n",
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 83.76 seconds\n",
      "got prompt\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 6803.592384338379 159.55708122253418 True\n",
      "Requested to load SDXL\n",
      "loaded completely 7665.473330307007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      " 70%|███████   | 28/40 [00:16<00:06,  1.72it/s]got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 130.43 seconds\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 7348.826759338379 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "loaded completely 7665.473330307007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 130.34 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 1025.3686828613281 159.55708122253418 True\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.87 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.94 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      " 57%|█████▊    | 23/40 [00:13<00:09,  1.71it/s]got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.97 seconds\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 7498.856056213379 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "loaded completely 7665.473330307007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      " 78%|███████▊  | 31/40 [00:16<00:04,  1.84it/s]got prompt\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 102.68 seconds\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 7348.826759338379 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "loaded completely 7665.473330307007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "got prompt\n",
      "Prompt executed in 130.30 seconds\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 7348.826759338379 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "loaded completely 7665.473330307007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 129.63 seconds\n",
      "got prompt\n",
      "model weight dtype torch.float16, manual cast: None\n",
      "model_type EPS\n",
      "Using pytorch attention in VAE\n",
      "Using pytorch attention in VAE\n",
      "VAE load device: cuda:0, offload device: cpu, dtype: torch.bfloat16\n",
      "Requested to load SDXLClipModel\n",
      "loaded completely 9.5367431640625e+25 1560.802734375 True\n",
      "CLIP/text encoder model load device: cuda:0, offload device: cpu, current: cuda:0, dtype: torch.float16\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 7348.826759338379 159.55708122253418 True\n",
      "loaded completely 9683.435889053344 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "loaded completely 7665.473330307007 4897.0483474731445 True\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load SDXL\n",
      " 38%|███▊      | 15/40 [00:08<00:13,  1.84it/s]got prompt\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 130.25 seconds\n",
      "loaded completely 4945.896710205078 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 480.1343078613281 159.55708122253418 True\n",
      " 92%|█████████▎| 37/40 [00:21<00:01,  1.71it/s]got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 77.17 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 1025.3686828613281 159.55708122253418 True\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.85it/s]\n",
      "Prompt executed in 74.87 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      " 52%|█████▎    | 21/40 [00:11<00:10,  1.84it/s]got prompt\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.84it/s]\n",
      "Prompt executed in 74.97 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      " 40%|████      | 16/40 [00:09<00:14,  1.61it/s]\n",
      "Processing interrupted\n",
      "Prompt executed in 33.89 seconds\n",
      "got prompt\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.84it/s]\n",
      "Prompt executed in 74.79 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n",
      "100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 40/40 [00:21<00:00,  1.84it/s]\n",
      "Prompt executed in 81.82 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 50/50 [00:30<00:00,  1.65it/s]\n",
      "100%|██████████| 50/50 [00:30<00:00,  1.66it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 50/50 [00:28<00:00,  1.77it/s]\n",
      "Prompt executed in 94.93 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.65it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 25/25 [00:13<00:00,  1.79it/s]\n",
      "Prompt executed in 47.44 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.65it/s]\n",
      "100%|██████████| 20/20 [00:12<00:00,  1.67it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 15/15 [00:08<00:00,  1.80it/s]\n",
      "Prompt executed in 41.81 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.65it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 15/15 [00:08<00:00,  1.80it/s]\n",
      "Prompt executed in 41.81 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 25/25 [00:15<00:00,  1.65it/s]\n",
      "100%|██████████| 20/20 [00:11<00:00,  1.67it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 15/15 [00:08<00:00,  1.79it/s]\n",
      "Prompt executed in 41.89 seconds\n",
      "got prompt\n",
      "loaded completely 4786.339628982544 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.04it/s]\n",
      "Prompt executed in 41.55 seconds\n",
      "got prompt\n",
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/home/sagemaker-user/ComfyUI/models/rembg/u2net.onnx'.\n",
      "100%|███████████████████████████████████████| 176M/176M [00:00<00:00, 1.34TB/s]\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 2451.730499267578 159.55708122253418 True\n",
      "loaded completely 4786.339628982544 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 41.64 seconds\n",
      "got prompt\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 2451.730499267578 159.55708122253418 True\n",
      "loaded completely 4786.339628982544 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.78it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 39.88 seconds\n",
      "got prompt\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 2451.730499267578 159.55708122253418 True\n",
      "loaded completely 4786.339628982544 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 38.68 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 1025.3686828613281 159.55708122253418 True\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.78it/s]\n",
      "Requested to load SDXL\n",
      " 45%|████▌     | 9/20 [00:02<00:03,  3.02it/s]got prompt\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.04it/s]\n",
      "Prompt executed in 36.20 seconds\n",
      "loaded completely 4786.339628982544 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 38.41 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 1025.3686828613281 159.55708122253418 True\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.17 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.12 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.11it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.78it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.17 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.83it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.07 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.82it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.03 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.82it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "got prompt\n",
      "Prompt executed in 36.00 seconds\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.82it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.00 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.77it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.18 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.10 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.12it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.11 seconds\n",
      "got prompt\n",
      "Device set to use cuda:0\n",
      "loaded completely 4786.339628982544 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.78it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 49.70 seconds\n",
      "got prompt\n",
      "Device set to use cuda:0\n",
      "Requested to load AutoencoderKL\n",
      "loaded completely 197.78498077392578 159.55708122253418 True\n",
      "Requested to load CLIPVisionModelProjection\n",
      "loaded completely 8170.504950332642 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "loaded completely 6721.146158981323 2395.547637939453 True\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:48<00:00,  1.62s/it]\n",
      "loaded completely 10430.781817245483 4897.0483474731445 True\n",
      "100%|██████████| 25/25 [00:31<00:00,  1.26s/it]\n",
      "Requested to load SDXL\n",
      "loaded completely 10430.781676101684 4897.0483474731445 True\n",
      "100%|██████████| 20/20 [00:23<00:00,  1.19s/it]\n",
      "Prompt executed in 136.62 seconds\n",
      "got prompt\n",
      "Requested to load CLIPVisionModelProjection\n",
      "loaded completely 11033.241011428832 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:49<00:00,  1.66s/it]\n",
      "100%|██████████| 25/25 [00:31<00:00,  1.27s/it]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:23<00:00,  1.19s/it]\n",
      "Prompt executed in 131.03 seconds\n",
      "got prompt\n",
      "Device set to use cuda:0\n",
      "loaded completely 11244.238631057739 1208.09814453125 True\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 40.98 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "100%|██████████| 30/30 [00:14<00:00,  2.06it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 36.47 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 38.67 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 38.73 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.07it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.71it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 38.66 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.13it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.79it/s]\n",
      "Requested to load SDXL\n",
      "100%|██████████| 20/20 [00:06<00:00,  3.05it/s]\n",
      "Prompt executed in 38.09 seconds\n",
      "got prompt\n",
      "Requested to load SDXL\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mINFO: the IPAdapter reference image is not a square, CLIPImageProcessor will resize and crop it at the center. If the main focus of the picture is not in the middle the result might not be what you are expecting.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:12<00:01,  2.60it/s]"
     ]
    }
   ],
   "source": [
    "!pip install rembg\n",
    "!sudo apt-get update && sudo apt-get install -y libgl1-mesa-glx\n",
    "# Put ComfyUI command line args here\n",
    "args = \"--preview-method auto --enable-cors-header --use-pytorch-cross-attention\"\n",
    "\n",
    "from threading import Timer\n",
    "from queue import Queue\n",
    "import os\n",
    "    \n",
    "def launch_comfy(args):\n",
    "    print(f'Wait for local URL to appear')\n",
    "    os.system(\"python ./ComfyUI/main.py \" + args)\n",
    "    \n",
    "launch_comfy(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013f2cd4-fd2f-4721-81d0-082b3839370f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
